# 汎用人工知能

計算機科学の未解決問題
汎用人工知能は実現可能なのか？また、実現可能だとすればどのように実現できるのか？	Question mark2.svg
汎用人工知能（はんようじんこうちのう、英:Artificial general intelligence、略称:AGI）とは、人間が実現可能なあらゆる知的作業を理解・学習・実行することができる人工知能である。人工知能の研究においては主要かつ最終的な目標であるとみなされており、未来学やSFにおいて話題に上がることが多い。数多くの企業・研究機関が汎用人工知能の達成に取り組んでおり、代表的な企業としてはOpenAI、DeepMind、Anthropicなどが挙げられる。

汎用人工知能は未だ実現しておらず、一般的には今後数十年以内に実現すると見積もられているが、汎用人工知能は将来的にも絶対に完成しないとする少数派の意見も存在する。さらに深層学習などによって作成された「GPT-4（ChatGPT）が汎用人工知能の初期バージョンである」という論文も存在するが、これには様々な肯定的意見と否定的意見があり、一貫した意見は存在しない。GPT-4（ChatGPT）は多くの人間向けのテストにおいて人類の平均的な点数を上回ることができることが確認されているが、これが汎用人工知能であるかについては論争が尽きない。

2020年の調査では、全世界において37カ国で汎用人工知能の研究・開発が行われており、さらに72個のプロジェクトが進行中であることが確認されている。

定義
汎用人工知能の他の呼称としては「強いAI」や「フルAI」、「ジェネラル・インテリジェント・アクション（英:general intelligent action）」などがあるが、一般的な学術的文章においては感性や意識を有するコンピュータプログラムに対しては「強いAI」という言葉を使用することが多い[注釈 1]。

強いAIの対照的な存在として考えられているのが弱いAI（英語版）（特化型人工知能）である。弱いAIは1つの問題を解決するために設計されたプログラムであり、学術的には人間のような意識や心を持たないものであると定義されている。弱いAIの代表例として知られるのがSiri、Alexa、Google アシスタントなどである。

人工知能研究においては、人工知能を性能のレベル別に見て、3つに分けることがある。

特化型人工知能（略:ANI）: 1つの問題を解決する事に特化した人工知能。特定の問題では人間の能力を凌駕することがあるが（コンピュータチェスなど）、人間のように多種多様な問題に対して柔軟に取り組むことはできない。今まで開発されたほぼ全ての人工知能がこれに含まれる。
汎用人工知能（略:AGI）: 人間と同等の知能を持った人工知能。人間は様々な問題に対して柔軟に対処することのできる「汎用知能」を持つが、汎用人工知能はこれを人工的に再現する。詳細は本記事を参照。
人工超知能（略:ASI）: 人間の知能を全ての面において超えた人工知能。人工超知能が誕生した場合、それは当然として人間の知能を超えた思考を持つため、本質的にどのような挙動をするかという予想が困難とされる。詳細は#人工超知能を参照。
概要
詳細は「人工知能」を参照
「知能」をどのように定義し、基準とするかは様々な意見が存在し、統一的な意見は存在しない。人工知能の知能をテストする方法として最も有名なのはチューリングテストである[注釈 2]。

知能の特色
しかしながら、どのような要素で「知能」が組み立てられているかは考察できる。人工知能の研究者間で広く認められている「知能」を構成するのに必要な要素は以下である。

自動推論を行える。戦略を練ることができる。パズルを解くことができる。不確実性がある状況下で結論を下すことができる。
知識表現ができる。常識知識（英語版）を有する。
自動計画ができる。
機械学習ができる。
自然言語処理によってコミュニケーションをとることができる。
さらに、これらの能力を統合（人工知能のシステム統合（英語版））することが求められる。その他に重要な要素は以下である。

見る、聞くといった能力によって情報をインプットすることができる。
それらの情報を元に、行動をアウトプットできる。（例えばロボット工学の技術によって自らの位置を移動させたり、など）
また、危険を回避するなどといった行為によって知的な行動を確認することができる。知能に関する学際的研究（認知科学、計算知能研究、意思決定研究）では、知能を測るにあたって想像力（プログラム外の心象や概念などを把握できる能力）や自律性などを考慮する傾向にある。

意思決定支援システム、ロボット、進化的計算、知的エージェント、計算総合性（英語版）など、これらの能力を獲得しているように見えるコンピュータープログラムは存在するが、すべての分野において優れている統合システムについては未だかつて実現したことはない。

人間レベルの汎用人工知能かを判別するためのテスト
汎用人工知能が人間レベルにまで達しているかを確認するためのテストとして、以下のようなものが考案されている。

チューリング・テスト（アラン・チューリング）
人間が機械を直接的に確認できないように隔離し、文字のみでのコミュニケーションをする。判定者となる人間が高い確率でコミュニケーションの相手が機械であるかどうか判別出来なかった場合、このテストに合格したことになる。注意すべきなのは、チューリングは知能の定義を規定していたわけではなく、ただ人間を騙せた場合において合格であると設定したのみであることである。つまりこのテストに合格したからといって、合格した機械が明確に知能を有するとは断言できない。
コーヒー・テスト（スティーブ・ウォズニアック）
平均的なアメリカの家庭を機械に訪問させ、コーヒーを淹れられるかどうかを試すテスト。このテストに合格可能な機械はコーヒーマシンを見つけ、コーヒー豆を探し、マグカップを取り出し、適切なボタンを押す能力があるとみなされる。
ロボット大学生テスト（ベン・ゲーツェル（英語版））
機械に大学入試テストを受けさせる。さらに人間と同じように講義に参加させ、学位を取得させる。
就職試験 （ニルス・ジョン・ニルソン（英語版））
機械に就職活動を行わせ、人間と同レベルに仕事ができるかどうかを観察する。
上記に挙げたテスト群は、いずれも弱いAIによってでも合格できる可能性がある。根本的に、汎用人工知能が実現したとしても、それが「知能的」であるかどうかをテスト・判別することはできないという立場の研究者も存在する。

AI完全問題
詳細は「AI完全」を参照
機械が人間と同じように課題を解決するためには、当然だが一般的な知能を必要とする。例えば機械翻訳のような単純作業においてさえ、機械は両方の言語を読み書きし（自然言語処理）、著者の主義主張を追い（推論）、どのような話題であるかを知り（知識）、文章の裏にある著者の本当の意図を忠実に再現（社会的知性）する必要がある。つまり人間レベルの知能にまで達するには、これらの能力すべてを獲得していなければならない。

ある特定の問題を解決すること仮定する。その問題を解決するのに必要な能力が、人間あるいは強いAIと同レベルの能力を要求し、特化型人工知能（弱いAI）には解決出来ない問題である場合、この問題は非公式に「AI完全」あるいは「AI困難」と呼ばれる。AI完全問題では、一般的なコンピュータビジョンや自然言語理解、現実世界では当然起こり得る予期せぬ出来事への対処などを想定している。

AI完全問題は、今現在のコンピュータ技術において解決は不可能である。この問題を解くには人間の知能が必要であり、この性質を利用したシステムなども作られている。例えばCAPTCHAのような技術によって人間かロボットかを判別したり、総当たり攻撃によってコンピュータセキュリティの突破を阻止する技術などが挙げられる。

数学公式化
汎用人工知能を数学的にどのように定義するかについては、2000年にコンピュータ科学者であるマーカス・ハッター（英語版）によって提案されたAIXI（英語版）モデルが存在する。AIXIモデルでは「未知なる環境下においても目標を達成できる能力」を最大化する。人間の行動を模倣するのではなく、知能の数学的定義を最大化するタイプの汎用人工知能は普遍的人工知能（英:universal artificial intelligence）と呼ばれることもある。

2015年、マーカス・ハッターとジャン・リーケは「Legg-Hutter知能は不変の万能チューリング機械（UTM（英語版））を基準にして測定し、もしそのように測定すればAIXIモデルが最も知能的である（つまりAIXIのパレート最適性は主観的である可能性）」ことを示した。これはAIXIのパレート最適性を覆す結果であった。この問題はAIXIが知能の代用として圧縮を用いたことに起因すると考えられており、認知は環境から切り離されて行われる必要があるとされる。これは哲学の領域で実体二元論として知られるものを公式化したものである。しかしながら現成主義（英語版）、すなわち認知は目標を追求する環境下において成り立つとされる考え方を支持する科学的根拠が多数存在する。その後、この問題を受けてマイケル・ティモシー・ベネットは現成主義認知を形式化し、「弱点」と呼ばれる知能の代用を特定した。弱点と圧縮の数学的証明による比較実験によって、弱点を最大化すると「様々な問題を解決する能力」あるいは「普遍化能力」が最大になることが示された。つまり結果としては、先程の定義とAIXI、どちらの定義を使っても知能が最大となり、同じであったのである。これらの研究結果により、もし現成主義が成立し実体二元論が成立しないと仮定したならば、圧縮は知能を構成する要素として必要あるいは十分ではないことが明らかになった。こうした経緯によって広く普及している知能に関する見解に疑問が投げかけられた。これらの人工知能に関する数学的問題はハッター賞（英語版）で盛んに議論されている。

数学公式化によって導かれた汎用人工知能は、認知に関する立場を問わず自然言語の使用といった人間的な行動を取るかは不明である。人間的な行動をするかどうかは多くの要因に依存し、どのようにエージェントが具体化されるか、飢えや痛みなどの原始的な報酬関数を定めるかによって左右されるからである。

歴史
古典的な人工知能研究
詳細は「人工知能の歴史」および「シンボリック人工知能」を参照
1950年代から現代的な人工知能研究が始まった。当時の人工知能研究者は楽観的であり、多くの第1世代人工知能研究者たちは、今後数十年以内において汎用人工知能が実現すると確信していた。人工知能研究のパイオニアであったハーバート・サイモンは1965年にこう書き記している。

今後20年以内に、機械は人間が実現可能なあらゆる仕事をできるようになるであろう。
— ハーバート・サイモン
この種の予想はアーサー・C・クラークの小説を元に制作された映画「2001年宇宙の旅」に登場するHAL 9000と呼ばれる人工知能を搭載したキャラクターから大いに影響を受けていた。初期の人工知能研究者であるマービン・ミンスキーは、当時の楽観的な予想に基づいてHAL9000を可能な限り現実化するプロジェクトのコンサルタントを務めていたこともある。ダニエル・クラヴィエ（英語版）は1967年にこのように発言している。

今後、一世紀以内に人工知能を作るという問題は実際的に解決されるであろう。
— ダニエル・クラヴィエ
汎用人工知能の研究として特筆すべき初期の研究は、ダグラス・レナート（英語版）主導のCycプロジェクトやアレン・ニューウェル主導のSoar (認知アーキテクチャ)プロジェクトなどが挙げられる。

しかしながら1970年代初頭から1990年代初頭にかけて、人工知能研究者たちはこのプロジェクトの難易度を甚だしく過小評価していたと自覚しつつあり、初期の楽観主義は長くは続かなかった。人工知能研究に出資していた出資者たちは早急に使い勝手の良い「応用可能なAI」[注釈 3]を開発するよう、プレッシャーを強めていった。1980年代に入ると、日本の国家プロジェクトである第五世代コンピュータが汎用人工知能への関心を呼び起こした。このプロジェクトでは10年の期間内で、「カジュアルな会話を行える」汎用人工知能を作ることなどが目標の1つとして挙げられていた。さらにエキスパートシステム開発の成功に反応して、産業界は再び人工知能分野に資金を提供し始めた。しかし、1980年代後半に入ると人工知能に対する期待は完全に消滅し、日本の第五世代コンピュータも失敗に終わった。20年前に人工知能研究者たちが出していた予想が悉く外れたことも影響し、1990年代に入ると、人工知能研究者は「空約束ばかりする学者集団」という評価を受けるようになった。そのころになると、人工知能研究者たちは「バカバカしい夢想家」という汚名を避けるために、「人間レベルの人工知能」についての発言や予想[注釈 4]を意図的に避けるようになった。

特化型人工知能（弱いAI）の研究
詳細は「人工知能」を参照
1990年代から21世紀初頭にかけて、人工知能の研究は主にニューラルネットワークや統計的機械学習に焦点が当てられてきた。その結果として確証可能な結果や商業的応用が可能になり、学術的評価と共に従来を上回る成果を達成した。現代社会において、これらの「特化型人工知能」はありとあらゆる産業全体で使用されており、学術界および産業界両方において多額の資金が供給されている。2020年以降、「特化型人工知能」分野の研究・開発はトレンドであり、完全な停滞期にまで達するには今後10年以上の歳月が必要になると推定されており、さまざまな部分問題を解決するプログラムを開発することが人工知能研究の主流になっている。弱いAIを開発し、それらの統合することによって結果的に強いAIの達成を図ろうとしている研究者も存在する。1988年、人工知能研究者であるハンス・モラベックはこう述べている。

私はこう確信している。つまり、人工知能を「下」から研究していくことによって、伝統的な「上」からの研究を上回ることができると。これを続けていくことによって、いつの日か人工知能は推論プログラムによって、これまで捉えようがなかったような常識的知識と応用能力を手にするであろう。そして「上」と「下」の研究成果を統合するゴールデン・スパイクが打たれたその瞬間、完全な人工知能が誕生するであろう。
しかしながらこの考えには異論も存在する。例えばプリンストン大学教授のスティーバン・ハーナッドは、1990年に「シンボルグラウンディング問題」論文の最後にこう書いている。

認知をモデル化するための「上」からのアプローチはやがて「下」からのアプローチと統合しうると声高に叫ばれている。しかしこの論文内での考察が正しいのならば、そういった期待は絶望的なまでに単純化されていると言わざるを得ない。感覚からシンボルへ実現可能な方法は唯一つ、一からやり直すしかない。
現代の汎用人工知能に関する研究
1997年、人工知能研究者であるマーク・グブルドは、自動化された軍事作戦について研究する過程において、「汎用人工知能」という単語を提唱した。

2002年、シェーン・レッグ（英語版）とベン・ゲーツェル（英語版）はこの用語をより一般に普及させた。2006年には、ベン・ゲーチェルと王培（Pei Wang）によって汎用人工知能の初期的な研究が行なわれた。

2009年、中国の厦門大学において、汎用人工知能に関する最初の夏期講習会が開かれた。これは厦門大学人工知能研究所とOpenCog（英語版）が主催を務めて行なわれたイベントであった。

2010年と2011年にかけて、ブルガリアのプロヴディフ大学では、汎用人工知能に関しては初となる大学における専門課程が設置された。2018年にはマサチューセッツ工科大学においても汎用人工知能に関する専門課程が設置されている。

2017年、刘峰（Feng Liu）、Yong Shi、Ying Liuらは、Google AIやSiriなど、一般的に使用されている弱いAIに対して知能検査を行った。その結果、平均IQは約47であることが判明した。この数値は人間に換算すれば6歳児程度に相当する。

2020年1月、マイクロソフトは「汎用人工知能を開発し人類に利益をもたらすこと」を目標として設立された研究所であるOpenAIに100億ドル（約1兆2800億円）を投資した。

2020年6月11日、OpenAIは自己回帰型言語モデルである「GPT-3」を発表した。GPT-3は汎用人工知能ではないというコンセンサスが取れているが、とはいえ弱いAIとするにはやや高性能すぎるという指摘がある。

2021年、DeepMindは「汎用」システム「Gato (DeepMind)（英語版）」を発表した。600個以上の異なる課題を解決できるとされる。

2023年、OpenAIはGPT-3の後継にあたる「GPT-4」を発表した。マイクロソフトの論文によれば、この言語モデルはこれまでの人工知能とは一線を画しており、「驚くほど人間の能力に近付いている」としている。そのため、「汎用人工知能の初期バージョンである可能性がある」と論文の中で記述している。

汎用人工知能の実現可能時期
汎用人工知能がいつ頃実現するかについては諸説あり、今後何世紀もの科学的努力を重ねても、汎用人工知能が実現可能なのかということは基本的な関心となっている。人工知能研究者の多くは、早くとも遅くとも将来的には汎用人工知能が実現可能であると考えている。コンピュータ科学者であるジョン・マッカーシーは、汎用人工知能はいずれかは達成されるとしているが、研究速度には不確実性が伴うため、いつ実現するかという正確な予想は不可能であるとしている。

2006年、ベン・ゲーチェルが発行した書籍内においては、真に柔軟な汎用人工知能が実現する時間は10年から100年の間とかなり開きがある。2007年にレイ・カーツワイルが発行した「The Singularity Is Near（英語版）」においては、主な汎用人工知能研究コミュニティの合意としては、2015年から2045年までに達成する可能性が高いとしている。しかしながらこの意見にはさまざまな異論があり、2045年までに汎用人工知能が達成されるほど研究の進歩が加速するかという点においては議論の余地がある。

汎用人工知能の実現可能性についての専門家の見解は一貫しておらず、時代によって変わる。2010年代に入ってからは、汎用人工知能の実現を支持する声が増加している傾向にある。2012年に行なわれたメタ解析によれば、汎用人工知能の誕生が今後16年から26年の間に行われる可能性が高い、という意見にバイアスがかかっていることが示唆されている。2012年と2013年に実施された4つの調査においては、実現可能時期の中央値は2040年から2050年で、平均値は2081年だった。さらに厳しい条件で質問すると、16.5％の専門家が「実現不可能」だと答えた。

しかしながら、このような時期に関する予想は科学的な正確性がなく、ロドニー・ブルックスは「この60年間で行われた汎用人工知能に関する予想は、どの時点においても15年後から25年後の間と予想する強い傾向がある」と報告している。これらの結果は、専門家と非専門家の間で実現予想の正確性の差がないことを強く示唆している。

このように、汎用人工知能の実現時期に関する研究者の反応は多種多様である。知能は未だ複雑すぎて完全には複製できないと主張する研究者も存在する。とはいえ、汎用人工知能に肯定的な研究者も数多くおり、様々な会社・グループの設立や会議、研究を行っている。

脳のシミュレーション
全脳エミュレーション
詳細は「精神転送」を参照
汎用人工知能を達成するためのアプローチとしてしばしば議論される方法が、脳のシミュレーションや精神転送である。低レベルの精神転送では、生物の脳をスキャン・マッピングし、その状態をコンピュータ内においてコピーすることで実現される。もしこれが実現するとするならば、コンピュータはオリジナルの脳と同等の振る舞いをすることが期待され、その振る舞いにおいては本質的あるいは実用的にオリジナルの脳と区別できないこととなる。脳のシミュレーションや精神転送は計算論的神経科学や神経情報科学の分野において、おもに医学研究を目的に研究されている。また、人工知能研究においても強いAIを実現するアプローチとして議論されている。レイ・カーツワイルは著書「The Singularity Is Near」内において、脳内のシミュレーションはいずれ可能になると予想している。

初期の研究

人間の脳を様々な方法でエミュレートするために必要なコンピュータの処理能力の推定値と、TOP500で示された年ごとのスーパーコンピューターの処理能力の図。傾向で見れば、コンピュータの処理能力が1.1年ごとに2倍になっている。カーツワイルは神経シミュレーションを達成した段階で精神転送が可能になると主張しているが、人間の意識がどこの段階で発生するかについては、専門家の間で意見が分かれている。
低レベルの脳のシミュレーションを実行するだけでも、非常に強力なコンピュータが必要になる。ヒトの脳には膨大な数のシナプスが存在し、その数は10の15乗であり、ニューロンは10の11乗存在する。この数は3歳児ごろにおいてピークに達し、その後は年齢と共に減少していき、成人に達する頃には安定する。ニューロンの活動を単純なスイッチモデルとして考えると、1秒間に10の14乗シナプスの更新ができるということになる。

1997年、カーツワイルは人間の脳と同等のハードウェアを実現するためにはどのぐらいの計算能力が必要か、ということについて考察し、最終的には1秒間に10の16乗（cps）の計算能力があれば実現可能とした[注釈 5]。カーツワイルはこの数字をもとに、執筆時（1997年当時）のコンピュータの指数関数的な成長が続けば、2015年から2025年の間に、理論的には人間の脳を十分に模倣できるだけのコンピュータが誕生すると予想した。ちなみに、現在のスーパーコンピューターの評価指標であるFLOPS1回分を「計算」と仮定すると、10の16乗の計算能力は2011年に達成されており、2022年には10の18乗の計算を行うことができるエクサスケールコンピュータが誕生している。

ニューロンの詳細なモデル化
人工ニューラルネットワークと呼ばれる人間の脳細胞を模したモデルは、実際の人間の生体神経と比較すると単純的かつ簡略的である。脳シミュレーションを完全に実行するためには、現在の研究ではまだ大まかにしか解明されていない生物学的な神経細胞の詳細な挙動を解明しなければならない可能性がある。神経細胞の生物学的、化学的、物理的な詳細な挙動を分子レベルにまで解明し、完全にモデル化するためには、カーツワイルが想定した計算能力よりもさらに強力な計算能力が必要になると見積もられている。さらに、カーツワイルの試算では人間の認知プロセスに深く関与しているとされるグリア細胞については考慮されていない。

現在の研究
2005年に、より高度で複雑な神経モデルを採用しつつ従来のコンピュータで脳のシミュレーションを実行しようとするプロジェクトが発足した。その研究内容によれば、コンピュータ上に「脳」（10の11乗のニューロンを実装）の非リアルタイムシミュレーションを実施した。しかしながら、1秒間のモデルを実行するのに対して50日間を要したという。

2006年、Blue Brainプロジェクトでは、IBMが所有していた当時世界最速のスーパーコンピュータであるBlue Geneを使用し、1万個のニューロンと108個のシナプスから構成されるラットの大脳新皮質の柱1本をリアルタイムでシュミュレーションすることに成功した。脳のシミュレーションに関する研究においての長期的な目標は、人間の脳の生理的プロセスの詳細を用いて、機能的なシミュレーションを構築することである。

2009年、オックスフォードで開催されたTED (カンファレンス)において、Blue Brainプロジェクトのリーダーであるヘンリー・マークラム（英語版）は「人間の脳を人工的に作成することは不可能ではなく、10年以内に実現する可能性がある」と発言している。また、有機工学の研究を活用して、人工的なニューロン（ニューロ・シリコン・インターフェース）を作成して脳のシミュレーションを行うというアプローチが、コンピュータ上での直接的な脳のシミュレーションが達成できなかった場合に有効であるという提言も行われている。

カーネギーメロン大学教授であり機械工学者であるハンス・モラベックは、1997年に発表した論文「コンピュータのハードウェアが人間の脳と同レベルになるのはいつ？」内で、脳はより複雑であり、ニューロンをより詳細にモデル化しなければ脳のシミュレーションを達成できないという議論について考察した。論文内において、神経細胞、特に網膜に焦点を当てて既存のソフトウェアがその機能をシミュレートする能力を測定した。

OpenWorm project（英語版）では、ニューロンがわずか302個しかない線形動物を、細胞レベルで完全にシミュレーションし、コンピュータ上に人工的な生命を作り出すことに目標として研究を開始した。このプロジェクトを開始する前には、人間に比べて遥かに単純な生物である線形動物をシミュレートするのは比較的容易であると予想されていた。しかしながらこれは失敗に終わった。この研究によって、生物のニューロンのモデル化は実際的には想像以上に困難であることが判明した。現在のプロジェクトでは、生物学的な神経細胞を精密にエミュレートすることに力を注いでいるが、未だ成功には至っていない。

脳のシミュレーションによって汎用人工知能を達成しようとするアプローチに対しての批判
根本的に、脳のシミュレーションによって汎用人工知能を達成しようとするアプローチ自体に対しての批判が存在する。これらの批判は、「人間は身体を持つから知性が存在する」という考えに基いてなされたものが多い。知性を誕生させるためには物理的な実体が必要であると考えている科学者も存在する。この考えが正しいと仮定すれば、完全に機能する脳のシミュレーションは、ニューロンを完全に再現しただけでは達成できず、ニューロン以上のもの、つまりロボットの身体などを内包する必要がある。ゲーチェルはこの批判に対して、人工知能に仮想的な身体（例えばSecond Lifeのような）を与えることで対処できるとしたが、これが有効かどうかは不明である。

2005年頃から、10の9乗以上の性能を持つデスクトップコンピュータが一般向けに販売されている。カーツワイルとモラベックが用いた推定によれば、これはミツバチの脳をシミュレートできるだけの能力を備えていることになる。しかしながら、ミツバチの脳をシミュレートできるソフトウェアはいまだ存在しない。これらの理由については幾つかの仮説が挙げられている。

現在のニューロンモデルが単純すぎる可能性。（次項参照）
より高次の認知プロセス[注釈 6]についての解明がいまだ不十分であり、fMRIなどによって観察されている脳の神経活動が、正確に何に相関するかを十分に確立できていない可能性。
認知プロセスに関する理解が十分に進んだとしても、初期のシミュレーションプログラムは非常に非効率であることが予想されるために、余計かつ多大な計算能力が要求される可能性。
生物の脳は重要ではあるが、脳だけを画一的に認知モデルとして採用するには不適切な可能性。そのため、ミツバチの脳をシミュレートするためには、身体や環境自体をもシミュレートしなければいけない可能性。
また、人間の脳の規模について、現在のところ完全に正確には特定できていない。ある説では、人間の脳には約1000億個のニューロンと100兆個のシナプスがあるというものがあるが、別の説においては大脳皮質に163億個、小脳に690億個のニューロンがあるともされている。グリア細胞に至っては、非常に多いということしかわかっていない。

哲学
哲学によって定義された「強いAI」
1980年、哲学者のジョン・サールは中国語の部屋と呼ばれる意識に関する思考実験を議論する過程において、「強いAI」という言葉を作り出した。この用語は、人工知能に関する以下のような2つの仮説を区別するために用いられた[注釈 7]。

「強いAI」仮説: 人工知能は「思考」することができ、「心」を持ち、「意識」を持つことが可能である。
「弱いAI」仮説: 人工知能は「思考」「心」「意識」があたかも存在するかのように振る舞っているだけであり、真に思考することは不可能である。
サールが前者の仮説を「強い」と表現したのは、これがより強い主張を行っているからである。強いAIは人間がテストできるすべての能力を超えた何かが機械に備わったことを仮定している。この思考実験においては、「弱いAI」と「強いAI」の振る舞いを外部から観察すれば同じに見えることになる。しかしながら「強いAI」には主観的な意識体験が存在することになる。これらの用語は学術的な人工知能の研究や教科書にも採用されている。

人工知能研究の主流では、プログラムがどのように機能するのかという点においてのみ主眼が置かれている。スチュアート・J・ラッセルとピーター・ノーヴィグはこう述べている。「プログラムが正常に動作しさえすれば、それをリアルと呼ぼうがシミュレーションと呼ぼうが、人工知能研究者は気にしない」。主流の人工知能研究者にとって、プログラムがあたかも心を持っているかのように完璧に振る舞っているとすれば、実際に心を持っているかを知る必要はない。というのも、心があるかないかを見分ける方法は存在しないからである。したがって、人工知能研究においてサールの「弱いAI仮説」は「汎用人工知能は実現可能である」と矛盾しない。

ラッセルとノーヴィグは「ほとんどの人工知能研究者は弱いAI仮説を当然のこととして受け入れており、強いAI仮説については全く関心がない」と発言している。このように、学術的な人工知能の研究にとっては、「強いAI」と「汎用人工知能」は全く異なるものである。

サールや主流の人工知能研究者とは対照的に、レイ・カーツワイルなどの一部の未来学者は「強いAI」という用語を「人間レベルの人工汎用知能」を意味するかのように使用している。これは人間レベルの汎用人工知能に意識が必要であると仮定しない限り、サールの「強いAI」の定義とは明確に異なっている。これらのことにサールのような学術的な哲学者や人工知能研究者は全く関心を示しておらず、信じてもいない。

意識
強いAIの意識に関連して、サイエンスフィクションや倫理面においては、心に関しても大きな関心が置かれている。

意識: クオリアや思考を持つ[注釈 8]。
自己認識: 自分を個人として認識すること。特に自分の思考を意識すること。
感性: 感情や知覚を主観的に「感じる」ことができる。
知恵: 物事の道理を理解し、判断できる。
このような、強いAIを有した機械の意識に対して関心がもたれる理由としては、もし機械が意識を持つならば、動物の権利と同じように、心を持つ機械にも人権が生じる可能性があるからである。そのために強いAIが発生した場合に備えて、既存の法律や倫理、社会の枠組みにどう心を持つ機械を統合するかというアプローチが研究されている。これらの研究は「強いAI」の法的位置づけと権利に焦点を当てている。コンピュータ科学者であるビル・ジョイは、このような心を持つ機械は、結果的に人間の生命や尊厳を脅かす可能性があると主張している。

これらの人間的な意識が「強いAI」に必要不可欠であるかどうかは不明である。そもそも意識を確認するための確実なテストは存在しないため、意識というものの役割が「強いAI」などのような影響をもたらすのかが明確ではない。仮に意識に相関した脳活動をシミュレートできる機械を作ったとしても、自動的に自己認識を持つようになるのかは不明である。意識は作成できるものではなく、汎用人工知能が作られた結果として自然に創発する可能性もある。また、機械が明らかに知的な行動を取るようになれば、これらの特徴を機械に帰属させることが自然になる可能性も存在する。

人工意識の研究
詳細は「人工意識」を参照
汎用人工知能・強いAIにおける意識の役割には議論の余地があるが、多くの汎用人工知能研究者は意識の実装を重要視している。

人工超知能
詳細は「超知能」を参照
人類で最も知能指数が高い天才をもはるかに上回る知能を持つ仮定上の知能を超知能と呼ぶ。デイヴィッド・チャーマーズは、汎用人工知能は超知能に至る可能性が高いと指摘している。なぜならば、人類と同程度の知能を持つ汎用人工知能が生み出されたと仮定したならば、それは自らのプログラムを改良可能であることを意味し、そしてプログラムが改良されたのならばその改良されたプラグラムによって生み出された知能を用いてさらに改良を続けることができ、これが延々と繰り返される。これは「再帰的自己改善（英:Recursive Self-Improvement）」と呼ばれる現象である。また、知能爆発や技術的特異点としても知られている。1965年にI.J.グッド（英語版）は以下のように発言している。

超知能機械を、どれだけ賢い人間よりも優れた知的能力をもつ存在だと仮定しよう。機械を設計することは知的能力によって行われることなので、超知能機械はさらに優れた機械を設計することができる。これが実行された瞬間、間違いなく「知能爆発」が起こり、人類の知的能力は瞬時にして置き去りにされることになる。したがって、超知能機械は人類最後の発明品ということになる。
— I・J・グッド（英語版）
汎用人工知能が超知能に至る可能性が高いとされているのは、自らの改良に生物学的な限度がないからである。一般的に、人間は産まれて成長しながら知能を増大させていく。しかしながらそれには生物学的・生理学的な制約が存在し、老化や死などの現象によって知能の成長は頭打ちになる。それに対して人工知能は拡張性があり、多くのスーパーコンピュータが毎年計算能力を増しているのと同じように、生物学的な制約（脳の大きさなど）が存在しない。

人工超知能
人工知能が超知能に達した場合、それを一般的に人工超知能（英:Artificial Super Intelligence、略称:ASI）と呼称する。

人工超知能が実現した場合、人類は本質的にその行動・思考・原理を理解できない可能性がある。この可能性はすでに現れており、例えば汎用人工知能や人工超知能にすら達していない特化型人工知能（弱いAI）のコンピュータ囲碁ソフトであるAlphaGoとトッププロ囲碁棋士である李世ドルが対局を果たしたAlphaGo対李世ドルにおいては、開発者ですらどのように動作しているか正確に理解できておらず、解説者を務めたマイケル・レドモンドは「これが良い手なのか悪い手なのか本当に理解できない」と述べている。

これは人工超知能が実現し、ある行動や決定をした場合、たとえその結果が正確なものであっても、その思考経緯が人間には理解できないほど複雑であり、数学的証明を求めようにもあまりにも長大すぎて理解できない可能性があるということを示唆している。2020年にローマン・ヤンポルスキー（英語版）はこう述べている。

人間は複雑な概念を説明しなければならないときがある。例えば、人間の大人が幼児や知的障害者などに「赤ちゃんはどこから来るの？」などという複雑な概念を質問された場合、我々はDNAや受精、子宮といったものではなく、答えを非常に簡略化したり、時には嘘を付いたりする。もちろん専門的で正確な説明をしてもいいが、そのような専門的な説明を幼児が理解できるかはわからないし、誤解をうむ可能性もある。説明の有用性は相対的なものであり、ある人にとっては理解できても、ある人にとっては理解できないことが往々にしてある。
超知能と人類の知能差は、おそらく人間の大人と幼児以上の差がある。これは知能の差がコミュニケーションの幅を非常に狭めることを意味する。そのため、超知能が導き出した概念を人間が理解するのは難しい。それはオオカミに育てられた知的障害のある４歳児に、量子物理学を教えるようなものである。

— ローマン・ヤンポルスキー（英語版）

問題・危険性
技術的失業
詳細は「技術的失業」を参照
歴史的に、科学技術の進歩によって、機械に置き換えられて存在しなくなった仕事が多数存在する（例えば電話交換手など）。しかしながらそれに伴って新たな労働が生まれることにより、人間の雇用の全体的な数は減少するのではなく、増加する傾向にある。一方、人工知能の進歩にも以前のような傾向が適応されるかという点については、経済学の観点からみても不明である。仮に汎用人工知能が実現した場合、それはもちろん人間に匹敵した知能を持つ。よって導入費用や心理的抵抗などの諸問題を無視すれば、人間に可能な知的労働は全て代替可能であることを意味する。

過去の機械化による失業は、主に単純作業などの低賃金労働者（ブルーカラー）に影響を与えたが、汎用人工知能による失業は中流階級に大きな影響をもたらす可能性がある。マサチューセッツ工科大学経済学部教授のデビッド・オーター（英語版）は「人工知能による労働環境の変化では、変化の幅において大いに不確実性を伴う。特に懸念すべきなのは、高賃金の仕事に就いている人々から職を奪い、フードコートの店員のような職しか残らないというようなことになるかもしれないということである」と指摘している。いずれにせよ、汎用人工知能が実現した場合には雇用、株式市場、福祉、税など、経済システム全体に大きな影響を与える可能性が高い

汎用人工知能による人類滅亡リスク
詳細は「汎用人工知能による人類滅亡のリスク」を参照
人類にとって人工知能は存亡の危機を左右する存在であり、そのリスクが高まっているという主張は多くの公人の間で広く支持されている。この危機を訴える著名人として代表的なのはスティーヴン・ホーキング、イーロン・マスク、ビル・ゲイツなどである。人工知能研究者としてこの危機を強く警鐘している人物として知られるのがスチュアート・J・ラッセルやローマン・ヤンポルスキー（英語版）、アレクセイ・ターチンなどである。しかしながら人工知能による人類滅亡リスクを気にしない人々も存在し、ビル・ゲイツは「一体なぜ心配しない人がいるのかが理解不能だ」と述べている。2014年にスティーヴン・ホーキングはこの危機に関する無関心を以下のように強く批判している。

もし人類より遥かに優れた文明を持つ異星人が「数十年後にそちらに到着する予定だ」とメッセージを送ってきたとき、我々はただ「わかった、着いたら連絡してね。待っとくよ」と返信してそのまま何もせずにしておくだろうか？しかしながら、これは人工知能においてまさにいま起こっていることだ。
— スティーブン・ホーキング
2021年、サンシャイン・コースト大学の人間工学者・社会情報システムセンターの研究者が実施した、汎用人工知能に関するリスクを分析する研究においては、データの少なさに苦言を呈しながらも、以下のような潜在的なリスクがあると結論づけられた。「汎用人工知能が人間の管理者や所有者のコントロール下から脱すること、汎用人工知能に人々に危害を与える命令を与えること、根本的に安全ではない汎用人工知能を開発すること、倫理観・道徳観がプログラミングされていない汎用人工知能を開発すること、そして汎用人工知能を不適切に管理することは、我々の実存的リスクを招く可能性がある」。

実存的リスク、すなわち人類滅亡の可能性は「AIのコントロール問題（英語版）」という難問を解決する必要がある。この問題を解決することが、人工知能を安全に管理する最善の方法だとみなされているが、大規模で非常にリソースが必要な研究であるとみなされている。人工知能のコントロール問題で重要視されるのは以下の概念である。すなわち「どのように自己複製を繰り返し、人間には遥かに理解できないほどの超知能を手に入れた人工知能を、人類に友好的な人工知能にできるのか？」ということである。汎用人工知能を各国が軍拡競争的に開発していくとすると、複数の国家によって汎用人工知能を搭載した軍事兵器の開発が行われることが想定される。汎用人工知能を前提とした国際紛争が発生した場合、軍事戦略をも汎用人工知能に頼ることになり、結果的には汎用人工知能同士が戦争を行うという自体もシナリオの１つとして研究されている。

もちろん、人工知能が人類滅亡を促すという考えには多くの懐疑主義者たちも存在する。懐疑主義者たちは、自己複製を繰り返して超知能が誕生する可能性（シンギュラリティ）自体を疑問視し、宗教的であると批判している。すなわち、神への信仰が人工知能にすり替わっただけではないか、という批判である。ジャロン・ラニアーは機械が知的になるという概念自体が金持ちによる「大規模な詐欺」である、と主張している。

汎用人工知能の実現への懐疑論
2023年現在、汎用人工知能は未だ実現していないため、すべては推論の域を出ていない。根本的に汎用人工知能が実現可能なのか、またいつ実現するのかについては様々な見解が存在し、統一されていない。そのために、根本的に汎用人工知能自体が実現不可能だと考える研究者もいる。1965年、人工知能のパイオニアとして知られるハーバート・サイモンは「今後20年以内に人間が実行できるあらゆる仕事が機械によってできるようになるだろう」と予想したが、この予想は完全に外れた。哲学者のヒューバート・ドレイファスやロジャー・ペンローズは、強いAI自体が根本的に実現不可能だと考えている。マイクロソフトの共同創業者であるポール・アレンは、汎用人工知能を実現するためには「根本的に予測不可能なブレイクスルー」と「認知に関する科学的な深い解明」が必要であるため、21世紀中には実現不可能だと予想している。ロボット工学者のアラン・ウィンフィールドはガーディアン紙に「現在のコンピュータ科学と汎用人工知能のレベルの差は、現在の宇宙飛行と光速を超える宇宙飛行と同じぐらいの差がある」と寄稿している。コンピュータ科学者であるゴードン・ベルは、人類は技術的特異点に到達する前に絶滅すると主張している。また、「ムーアの法則」の発案者として知られるゴードン・ムーアは「私は汎用人工知能の実現に懐疑的だ。なぜならば、技術的特異点は長い間起こりそうにないと思っているからだ。この感覚に根拠はない。そしてなぜそう感じるのかもわからない」と述べている

研究の遅延
「人工知能の歴史#AIの冬第1期 1974−1980#問題」および「人工知能の歴史#HAL 9000 はどこに? 2001年前後」も参照
1956年に人工知能の研究が始まって以降、人間に匹敵する知能を持つ機械を作成するというこの分野の進歩は、遅々として進んでいない。その原因として挙げられるのは、現在のコンピュータは計算機科学や神経科学を進めるために特化しておらず、これらの研究を推進するためのメモリや処理能力、柔軟性が欠けていることがなどが考えられる。また、そもそも人工知能研究が複雑すぎるために強いAIの進展を阻害している可能性もある。

概念上の限界が人工知能研究の遅れの原因であり、人工知能研究者は強いAIの実現に向けて概念的な枠組みを修正する必要があるとも考えられる。

この問題からはモラベックのパラドックスと呼ばれる根本的な矛盾が生じる。つまり、これまで作成されてきた人工知能は、膨大な数の計算やチェスのプレイなどといった人間には困難な仕事をこなすことは容易なのだが、逆に人間にとって簡単な「歩く」と言った動作や「1歳児レベルの知覚」といったものは難しいのである。とはいえ、これらのギャップは一部の労働者にとっては脅威になる場合がある。このパラドックスについて、ランジャニ・C・ナラヤンはこう記述している。

多くの人々は肉体労働が人工知能による自動化によって取って代わると思っているが、現実はその逆である。人工知能にとっては、知的に難しい仕事のほうが遥かに容易である。 別の言い方をすれば、チェスのグランドマスターであるマグヌス・カールセンを倒せるのは人工知能であり、その後の掃除をするのが人間である。
過去数十年に渡る人工知能研究における遅れは、人工知能分野そのものに対する不信感をも生み出し、その不信感が更に汎用人工知能の研究を妨げている。人工知能研究者が予想した結果が外れたり、人工知能が人間の行動を部分的にしか理解できないことによって、人間レベルの人工知能を作成するという原初の発想に対する極度の楽観主義は消滅した。とはいえ、人工知能に関する研究は失望や衰退を繰り返しながらも改善が進んでいるのは事実であり、多くの研究者は21世紀中には汎用人工知能が完成することに肯定的である。

他に提唱されている汎用人工知能の遅れの原因と考えられるのは、学問分野間での連携が取れていないことなどが挙げられる。具体的には、多くの汎用人工知能研究者はコンピュータ上で人間の脳を再現しようと試みてきたが、それらを達成するためには神経生理学や心理学において人間の脳を完全に理解することが必要不可欠である。しかしながら人工知能に関する研究者の多くは、人工知能の将来予測にかかわる疑念の多くを過小評価する傾向があり、人間の脳のモデル化といった本質的な問題の解決策を見落としている可能性がある。

ウィリアム・クロクシンは人工知能研究を妨げる概念上の理由として、人工知能研究者が装置やコンピュータプログラムを使用するに当たって、誤った技法を用いている可能性があると述べている。人工知能研究者が汎用人工知能を目標として研究を始めた当初、主な関心は人間の推論をエミュレートすることであった。初期の研究者たちは、人間の推論を通じて人間の知性の数学的なモデル化を確立し、特定の認知機能を持つコンピュータを設計する方法について研究していた。

これに対し、研究において抽象化・再定義をしつつ作業を進める方法を用いれば、人工知能研究者にとっては複雑な概念に取り組むよりも、数個の概念に集中できる。人工知能研究においては、計画と問題解決をする方法として抽象化を用いることが多い。これらの方法は計算の高速化を目的として用いられるが、あまりに抽象化しすぎると問題が生じることもある。

さらに挙げられる人工知能の研究が遅れている理由としては、多くの研究者が人間のひらめき（ヒューリスティクス）がコンピュータの性能よりも圧倒的に優れていると認めている点にある。しかしながら、よりコンピュータが高性能化すれば、人間のひらめきという能力すらも人工知能で再現できる可能性がある。ひらめきという人間の能力は、必ずしも強いAIを実現するための必須条件であるとはみなされていないが、大きな課題であることは広く認められている。

根本的には、そもそも機械に感情を持たせるべきなのかという問題が存在する。典型的な人工知能のモデルには感情という機能は実装されておらず、感情をプログラムとして実装することで初めて機械が感情を持つと主張するものもいる。しかしながら、人間の感情というものは、個々人がそれまで経験してきたことの総括として存在するものでもある。デヴィッド・ゲランター（英語版）は「人間の感情のニュアンスをすべてシュミレートできないかぎり、機械は創造的にはなれない」と発言している。このように感情に関する問題は多数存在し、強いAIの研究が発展するにあたっては、これらの問題に向き合う必要があると言える。
